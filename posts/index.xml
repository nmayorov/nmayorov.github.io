<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on My Blog</title><link>https://nmayorov.github.io/posts/</link><description>Recent content in Posts on My Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 04 May 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://nmayorov.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Extend Kalman Filter update step as an optimization problem</title><link>https://nmayorov.github.io/posts/ekf_update_optimization/</link><pubDate>Thu, 04 May 2023 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/ekf_update_optimization/</guid><description>The Extended Kalman Filter is classically built as an extension of the linear Kalman filter using system and measurement models linearization. In this regard the update step in EKF is naturally done in a single step. The iterated EKF aims to improve the linearization point by doing several update iterations and recomputing measurement Jacobian each time. It&amp;rsquo;s known to be connected with nonlinear optimization.
In this note I want to derive possible EKF update strategies starting from the optimization viewpoint.</description></item><item><title>Heading observability in Inertial Navigation Systems</title><link>https://nmayorov.github.io/posts/ins_heading_observability/</link><pubDate>Sun, 02 Apr 2023 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/ins_heading_observability/</guid><description>It&amp;rsquo;s generally known that the heading angle in Inertial Navigation Systems (INS) is observable when the system undergoes acceleration (including turns at nonzero velocity). However if we look at the &amp;ldquo;modified error model&amp;rdquo;, it may seem that merely significantly nonzero constant velocity is sufficient. Here I want to figure out this subject using formal observability criteria and then give it intuitive physical explanation.
INS equations in 2 dimensions Link to heading To investigate heading observability, a simplified version of INS for a 2-dimensional motion is fully sufficient.</description></item><item><title>Implementation of Kalman correction formulas</title><link>https://nmayorov.github.io/posts/practical_kalman_correction/</link><pubDate>Thu, 12 Jan 2023 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/practical_kalman_correction/</guid><description>This is a short note on my view how to best implement Kalman correction formulas in a programing language.
Basic formulas Link to heading A vector measurement is linearly related to a state vector with an additive noise: $$ z = H x + v $$ Where $z$ and $H$ are a known vector and matrix and the noise vector $v$ has a known covariance matrix $R$. Thus the measurement model is defined by 3 elements &amp;ndash; $z, H, R$.</description></item><item><title>Alternative form of Kalman smoother</title><link>https://nmayorov.github.io/posts/smoother_alt_form/</link><pubDate>Thu, 05 Jan 2023 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/smoother_alt_form/</guid><description>In this post (recommended to read beforehand) I&amp;rsquo;ve shown a derivation of the Kalman smoother as a solution to an optimization problem. The resulting formulas are surprisingly elegant, however their applicability depends on the assumption that apriori filter covariance matrices $P_k^-$ are positive definite and invertible. This assumption might be limiting in practical problems and thus another form of the Kalman smoother is derived here.
Motivating example Link to heading A singular covariance matrix may arise in the following practical scenario.</description></item><item><title>INS error equations</title><link>https://nmayorov.github.io/posts/ins_error_equations/</link><pubDate>Tue, 20 Dec 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/ins_error_equations/</guid><description>In this note I want to derive Inertial Navigation System (INS) error equations in concise and coherent fashion. This is of course a well known subject, however it&amp;rsquo;s useful to derive all the equations from scratch and revisit the subject from time to time.
INS state variables and equations for them Link to heading An Inertial Navigation System computes position, velocity and attitude of a moving object using gyro and accelerometer measurements from an Inertial Measurement Unit (IMU).</description></item><item><title>Noisy input in state time propagation: "control" vs. "navigation"</title><link>https://nmayorov.github.io/posts/time_propagation_noise/</link><pubDate>Sat, 10 Dec 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/time_propagation_noise/</guid><description>In this note I want to show that there are two possible scenarios how noisy input can influence state time propagation in estimation problems. This is not well articulated in classical literature and may create confusion when applying estimation algorithms to practical systems.
I will illustrate the concept on a simple example. Consider a robot which can move in the direction of its longitudinal axis and rotate. Its state is described by 4 variables (2D case):</description></item><item><title>Solving a nonlinear estimation problem by optimization</title><link>https://nmayorov.github.io/posts/nl_estimation_example/</link><pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/nl_estimation_example/</guid><description>Here I want to demonstrate how the proposed nonlinear estimation algorithm solves an example estimation problem.
Model formulation Link to heading As a dynamics system for variable $y$ I consider a nonlinear damped oscillator with an external force $a$: $$ \ddot{y} + 2 \eta \omega \dot{y} (1 + \xi \dot{y}^2) + \omega^2 \sin y = a $$ The difference from the linear model are:
The returning force is changed from $y$ to $\sin y$ &amp;ndash; this can be viewed as abandoning the small angle approximation for a gravity pendulum The friction force now nonlinear with an additional factor of $1 + \xi \dot{y}^2$ &amp;ndash; the friction increases for high speed Introducing the variables $$ x_1 \coloneqq y \\ x_2 \coloneqq \dot{y} \\ $$ we rewrite it as a first order system $$ \dot{x_1} = x_2 \\ \dot{x_2} = -\omega^2 \sin x_1 - 2 \eta \omega x_2 (1 + \xi x_2^2) + a $$ Introduce discrete time variables $$ x_k \coloneqq x(k \tau) \\ a_k \coloneqq a(k \tau) $$ Applying the first-order integration method we get the following discrete time equation: $$ x_{k + 1} = f(x_k, a_k) \\ \text{with }f(x, f) = \begin{bmatrix} x_1 + \tau x_2 \\ x_2 - \tau (\omega^2 \sin x_1 + 2 \eta \omega x_2 (1 + \xi x_2^2) + f) \end{bmatrix} $$ Let&amp;rsquo;s introduce the noise sources into it:</description></item><item><title>Nonlinear batch estimation</title><link>https://nmayorov.github.io/posts/nonlinear_batch_estimation/</link><pubDate>Wed, 30 Nov 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/nonlinear_batch_estimation/</guid><description>In this note I present a development of nonlinear batch estimation algorithm.
Model description Link to heading The state estimation problem in a nonlinear system is considered. The formulations is analogous to the linear case, but with nonlinear transition and measurement equations. We use uppercase letters to denote variables participating in the nonlinear model. Time transition and measurement equations for which are $$ Z_k = f_k(X_k) + V_k \\ X_{k+1} = h_k(X_k, W_k) $$ All the other assumptions remain the same.</description></item><item><title>Verification of Kalman filter and smoother algorithms</title><link>https://nmayorov.github.io/posts/verify_smoother/</link><pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/verify_smoother/</guid><description>In the previous post I&amp;rsquo;ve derived formulas for a batch state estimation &amp;laquo;Kalman smoother&amp;raquo; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method Link to heading The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm.</description></item><item><title>Derivation of Kalman smoother from an optimization perspective</title><link>https://nmayorov.github.io/posts/rts_as_optimization/</link><pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate><guid>https://nmayorov.github.io/posts/rts_as_optimization/</guid><description>In this post Kalman smoother formulas are derived as a solution to an optimization problem.
Problem formulation Link to heading We consider an estimation problem for a discrete time linear stochastic system: $$ \begin{gather*} x_{k+1} = F_k x_k + G_k w_k \\ z_k = H_k x_k + v_k \\ \operatorname{E} x_0 = x_0^- \\ \operatorname{E} (x - x_0^-) (x - x_0^-)^T = P_0^- \succ 0 \\ \operatorname{E} w_k = 0 \\ \operatorname{E} w_k w_k^T = Q_k \succ 0 \\ \operatorname{E} v_k = 0 \\ \operatorname{E} v_k v_k^T = R_k \succ 0 \\ \operatorname{E} w_i w_j^T = 0 \text{ for } i \neq j \\ \operatorname{E} v_i v_j^T = 0 \text{ for } i \neq j \\ \operatorname{E} w_i v_j^T = 0 \\ \end{gather*} $$</description></item></channel></rss>