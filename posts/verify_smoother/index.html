<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Verification of Kalman filter and smoother algorithms | Navigating Uncertainty</title>
<meta name=keywords content><meta name=description content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><meta name=author content="Nikolay Mayorov"><link rel=canonical href=https://nmayorov.github.io/posts/verify_smoother/><link crossorigin=anonymous href=/assets/css/stylesheet.a801c217e3c96db9c9df36cb1d2216a9bc5d9fa77b72e2afcdf47fb847f8f015.css integrity="sha256-qAHCF+PJbbnJ3zbLHSIWqbxdn6d7cuKvzfR/uEf48BU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://nmayorov.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nmayorov.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nmayorov.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nmayorov.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nmayorov.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script><meta property="og:title" content="Verification of Kalman filter and smoother algorithms"><meta property="og:description" content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><meta property="og:type" content="article"><meta property="og:url" content="https://nmayorov.github.io/posts/verify_smoother/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2022-11-29T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Verification of Kalman filter and smoother algorithms"><meta name=twitter:description content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://nmayorov.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Verification of Kalman filter and smoother algorithms","item":"https://nmayorov.github.io/posts/verify_smoother/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Verification of Kalman filter and smoother algorithms","name":"Verification of Kalman filter and smoother algorithms","description":"In the previous post I\u0026rsquo;ve derived formulas for a batch state estimation \u0026laquo;Kalman smoother\u0026raquo; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.\nMonte Carlo method The invaluable method of verification of estimation algorithms is Monte Carlo simulation:\nGenerate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\\Delta x_k = \\hat{x}_k - x_k$, where $\\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm.","keywords":[],"articleBody":"In the previous post I’ve derived formulas for a batch state estimation «Kalman smoother» algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.\nMonte Carlo method The invaluable method of verification of estimation algorithms is Monte Carlo simulation:\nGenerate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\\Delta x_k = \\hat{x}_k - x_k$, where $\\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm. Alternatively sample root mean squared errors (as $\\sqrt{\\operatorname{E} [\\Delta x_k]_i^2}$) can be compared with standard deviations provided by the estimation algorithm. This will check mean and covariance correctness simultaneously and this is the approach I usually use.\nI will use this method to verify the Kalman filter and smoother algorithms applied to the system described in the next section.\nModel formulation As a dynamic system I consider a damped linear oscillator which is described by the following differential equation for $y$: $$\\ddot{y} + 2 \\eta \\omega \\dot{y} + \\omega^2 y = f$$ With $\\omega \u003e 0$ being the oscillator frequency and $\\eta \\geq 0$ being a dimensionless damping factor and $f$ being an external force.\nIntroducing the variables $$ x_1 \\coloneqq y \\\\ x_2 \\coloneqq \\dot{y} \\\\ $$ we rewrite it as a first order system $$ \\begin{bmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{bmatrix} = \\begin{bmatrix} 0 \u0026 1 \\\\ -\\omega^2 \u0026 -2 \\eta \\omega \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} f $$\nFurther we assume that $f$ is a white noise process with a known power spectral density $q_f^2$. In this form we have a linear continuous stochastic process for $x$. To convert it to an equivalent discrete form we use a first-order discretization scheme. Let $\\tau$ be the sampling period and $$ x_k \\coloneqq x(k \\tau) $$ Then the discrete time system is $$ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}_{k + 1} = \\begin{bmatrix} 1 \u0026 \\tau \\\\ -\\omega^2 \\tau \u0026 1 - 2 \\eta \\omega \\tau \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}_k + \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} w_k $$ With $w_k$ being a white random sequence with the variance $q_f^2 \\tau$.\nNoisy measurements of $x_1$ and $x_2$ are available for each $k$ as $$ \\begin{bmatrix} z_1 \\\\ z_2 \\end{bmatrix}_k = \\begin{bmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}_k + \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}_k $$\nKnowledge on prior statistics on $x_0$ is also available: $$ \\operatorname{E} x_0 = x_0^- \\\\ \\operatorname{E} (x_0 - x_0^-)(x_0 - x_0^-)^T = P_0^- $$\nModel summary We have formulated a discrete time linear stochastic model in the standard form. The required matrices have the following form for our problem (they don’t depend on $k$).\nPrior mean: $$ x_0^- = \\begin{bmatrix} x_{01}^- \\\\ x_{02}^- \\end{bmatrix} $$\nPrior covariance matrix: $$ P_0^- = \\begin{bmatrix} \\sigma_{01}^2 \u0026 0 \\\\ 0 \u0026 \\sigma_{02}^2 \\end{bmatrix} $$\nTransition matrix: $$ F = \\begin{bmatrix} 1 \u0026 \\tau \\\\ -\\omega^2 \\tau \u0026 1 - 2 \\eta \\omega \\tau \\end{bmatrix} $$\nProcess noise input matrix: $$ G = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} $$\nProcess noise covariance matrix: $$ Q = \\begin{bmatrix} q_f^2 \\tau \\end{bmatrix} $$\nMeasurement matrix: $$ H = \\begin{bmatrix} 1 \u0026 0 \\\\ 0 \u0026 1 \\end{bmatrix} $$\nMeasurement noise covariance matrix: $$ R = \\begin{bmatrix} \\sigma^2_{z1} \u0026 0 \\\\ 0 \u0026 \\sigma^2_{z2} \\end{bmatrix} $$\nNumerical values Here I define which numerical values will be used in the simulation. For intuitiveness I assume that $x_1$ is measured in radians and $x_2$ in radians per second (imagine a simple gravity pendulum). Then dimensions of the other variables follow.\n$$ \\omega = \\frac{2 \\pi}{10} \\, \\text{Hz (period of 10 s)} \\\\ \\eta = 0.1 \\\\ q_f = 0.03 \\, \\frac{\\text{rad}}{\\text{s}\\sqrt{\\text{s}}} \\\\ \\sigma_{z1} = 0.2 \\, \\text{rad} \\\\ \\sigma_{z2} = 0.1 \\, \\frac{\\text{rad}}{\\text{s}} \\\\ x_{01}^- = 1 \\, \\text{rad} \\\\ x_{02}^- = 0 \\, \\frac{\\text{rad}}{\\text{s}} \\\\ \\sigma_{01}^- = 0.1 \\, \\text{rad} \\\\ \\sigma_{02}^- = 0.05 \\, \\frac{\\text{rad}}{\\text{s}} \\\\ \\tau = 0.1 \\, \\text{s} $$\nSimulation results I have used 10000 runs in the simulation. In each run the state for 1000 epochs was computed. For brevity and simplicity I don’t analyze correlation between the states (off-diagonal elements of the covariance).\nPlots for a single simulation run Plots of the variables for one run are depicted below. The plots in the second row enlarges the end part of the plots in the first row.\nAs you can see the true state behaves somewhat erratically, especially $x_2$ as directly affected by the noise. The same can be said for the filter estimates. Whereas the smoother estimates are indeed significantly smoother and qualitatively more accurate (closer to the true state).\nA plot for the noise during one run is depicted below.\nIt’s hard to say for certain just by one sample, but it looks like the smoother is able to estimate some «trends» in the noise sequence when they occur.\nComparison of sample RMS and estimated SD Below plots with sample root mean squared errors (RMS) and estimated standard deviations (SD) for $x_1, x_2$ and $w$ are presented.\nA plot for $w$ is done with a narrow y-axis range to demonstrate the difference between all depicted data.\nWe can make the following observations:\nThe agreement between sample RMS and estimated SD is very good The smoother does indeed gives lower error RMS than the filter The steady state smoother RMS is lower by the factor of approximately $\\sqrt{2}$ compared to the filter RMS The smoother performance is worse near the start and terminal epochs The noise vectors are marginally observable in this model, i. e. the smoother error RMS and SD are slightly lower than the noise standard deviation Conclusion Using Monte Carlo simulation I’ve demonstrated that Kalman filter and smoother generates estimates with statistical properties consistent with their internal covariance estimates. It is also true for the noise estimates of the Kalman smoother, which is not well known in the estimation literature and might seem somewhat dubious at first.\n","wordCount":"1060","inLanguage":"en","datePublished":"2022-11-29T00:00:00Z","dateModified":"2022-11-29T00:00:00Z","author":{"@type":"Person","name":"Nikolay Mayorov"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nmayorov.github.io/posts/verify_smoother/"},"publisher":{"@type":"Organization","name":"Navigating Uncertainty","logo":{"@type":"ImageObject","url":"https://nmayorov.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nmayorov.github.io accesskey=h title="Navigating Uncertainty (Alt + H)">Navigating Uncertainty</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nmayorov.github.io/archives title="All posts"><span>All posts</span></a></li><li><a href=https://nmayorov.github.io/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nmayorov.github.io>Home</a>&nbsp;»&nbsp;<a href=https://nmayorov.github.io/posts/>Posts</a></div><h1 class=post-title>Verification of Kalman filter and smoother algorithms</h1><div class=post-meta><span title='2022-11-29 00:00:00 +0000 UTC'>November 29, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Nikolay Mayorov</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#monte-carlo-method aria-label="Monte Carlo method">Monte Carlo method</a></li><li><a href=#model-formulation aria-label="Model formulation">Model formulation</a><ul><li><a href=#model-summary aria-label="Model summary">Model summary</a></li><li><a href=#numerical-values aria-label="Numerical values">Numerical values</a></li></ul></li><li><a href=#simulation-results aria-label="Simulation results">Simulation results</a><ul><li><a href=#plots-for-a-single-simulation-run aria-label="Plots for a single simulation run">Plots for a single simulation run</a></li><li><a href=#comparison-of-sample-rms-and-estimated-sd aria-label="Comparison of sample RMS and estimated SD">Comparison of sample RMS and estimated SD</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></div></details></div><div class=post-content><p>In the <a href=https://nmayorov.github.io/posts/rts_as_optimization/>previous post</a> I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm.
Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.</p><h1 id=monte-carlo-method>Monte Carlo method<a hidden class=anchor aria-hidden=true href=#monte-carlo-method>#</a></h1><p>The invaluable method of verification of estimation algorithms is Monte Carlo simulation:</p><ol><li>Generate a ground truth sequence of states and measurements according to the system model.
It assumes generating process and measurement noises as pseudorandom numbers</li><li>Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$,
where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$</li><li>Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$</li></ol><p>The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm.
Alternatively sample root mean squared errors (as $\sqrt{\operatorname{E} [\Delta x_k]_i^2}$) can be compared with standard deviations provided by the estimation algorithm.
This will check mean and covariance correctness simultaneously and this is the approach I usually use.</p><p>I will use this method to verify the Kalman filter and smoother algorithms applied to the system described in the next section.</p><h1 id=model-formulation>Model formulation<a hidden class=anchor aria-hidden=true href=#model-formulation>#</a></h1><p>As a dynamic system I consider a damped linear oscillator which is described by the following differential equation for $y$:
$$\ddot{y} + 2 \eta \omega \dot{y} + \omega^2 y = f$$
With $\omega > 0$ being the oscillator frequency and $\eta \geq 0$ being a dimensionless damping factor and $f$ being an external force.</p><p>Introducing the variables
$$
x_1 \coloneqq y \\
x_2 \coloneqq \dot{y} \\
$$
we rewrite it as a first order system
$$
\begin{bmatrix}
\dot{x}_1 \\
\dot{x}_2
\end{bmatrix} = \begin{bmatrix}
0 & 1 \\
-\omega^2 & -2 \eta \omega
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix} + \begin{bmatrix}
0 \\
1
\end{bmatrix} f
$$</p><p>Further we assume that $f$ is a white noise process with a known power spectral density $q_f^2$.
In this form we have a linear continuous stochastic process for $x$.
To convert it to an equivalent discrete form we use a first-order discretization scheme.
Let $\tau$ be the sampling period and
$$
x_k \coloneqq x(k \tau)
$$
Then the discrete time system is
$$
\begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_{k + 1} = \begin{bmatrix}
1 & \tau \\
-\omega^2 \tau & 1 - 2 \eta \omega \tau
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_k + \begin{bmatrix}
0 \\
1
\end{bmatrix} w_k
$$
With $w_k$ being a white random sequence with the variance $q_f^2 \tau$.</p><p>Noisy measurements of $x_1$ and $x_2$ are available for each $k$ as
$$
\begin{bmatrix}
z_1 \\
z_2
\end{bmatrix}_k =
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_k + \begin{bmatrix}
v_1 \\
v_2
\end{bmatrix}_k
$$</p><p>Knowledge on prior statistics on $x_0$ is also available:
$$
\operatorname{E} x_0 = x_0^- \\
\operatorname{E} (x_0 - x_0^-)(x_0 - x_0^-)^T = P_0^-
$$</p><h2 id=model-summary>Model summary<a hidden class=anchor aria-hidden=true href=#model-summary>#</a></h2><p>We have formulated a discrete time linear stochastic model in the <a href=https://nmayorov.github.io/posts/rts_as_optimization/#problem-formulation>standard form</a>.
The required matrices have the following form for our problem (they don&rsquo;t depend on $k$).</p><p>Prior mean:
$$
x_0^- = \begin{bmatrix}
x_{01}^- \\
x_{02}^-
\end{bmatrix}
$$</p><p>Prior covariance matrix:
$$
P_0^- = \begin{bmatrix}
\sigma_{01}^2 & 0 \\
0 & \sigma_{02}^2
\end{bmatrix}
$$</p><p>Transition matrix:
$$
F = \begin{bmatrix}
1 & \tau \\
-\omega^2 \tau & 1 - 2 \eta \omega \tau
\end{bmatrix}
$$</p><p>Process noise input matrix:
$$
G = \begin{bmatrix}
0 \\
1
\end{bmatrix}
$$</p><p>Process noise covariance matrix:
$$
Q = \begin{bmatrix}
q_f^2 \tau
\end{bmatrix}
$$</p><p>Measurement matrix:
$$
H = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$</p><p>Measurement noise covariance matrix:
$$
R = \begin{bmatrix}
\sigma^2_{z1} & 0 \\
0 & \sigma^2_{z2}
\end{bmatrix}
$$</p><h2 id=numerical-values>Numerical values<a hidden class=anchor aria-hidden=true href=#numerical-values>#</a></h2><p>Here I define which numerical values will be used in the simulation.
For intuitiveness I assume that $x_1$ is measured in radians and $x_2$ in radians per second (imagine a simple gravity pendulum).
Then dimensions of the other variables follow.</p><p>$$
\omega = \frac{2 \pi}{10} \, \text{Hz (period of 10 s)} \\
\eta = 0.1 \\
q_f = 0.03 \, \frac{\text{rad}}{\text{s}\sqrt{\text{s}}} \\
\sigma_{z1} = 0.2 \, \text{rad} \\
\sigma_{z2} = 0.1 \, \frac{\text{rad}}{\text{s}} \\
x_{01}^- = 1 \, \text{rad} \\
x_{02}^- = 0 \, \frac{\text{rad}}{\text{s}} \\
\sigma_{01}^- = 0.1 \, \text{rad} \\
\sigma_{02}^- = 0.05 \, \frac{\text{rad}}{\text{s}} \\
\tau = 0.1 \, \text{s}
$$</p><h1 id=simulation-results>Simulation results<a hidden class=anchor aria-hidden=true href=#simulation-results>#</a></h1><p>I have used 10000 runs in the simulation.
In each run the state for 1000 epochs was computed.
For brevity and simplicity I don&rsquo;t analyze correlation between the states (off-diagonal elements of the covariance).</p><h2 id=plots-for-a-single-simulation-run>Plots for a single simulation run<a hidden class=anchor aria-hidden=true href=#plots-for-a-single-simulation-run>#</a></h2><p>Plots of the variables for one run are depicted below.
The plots in the second row enlarges the end part of the plots in the first row.</p><p><a href=figs/state_sample.svg><img loading=lazy src=figs/state_sample.svg alt=state_sample></a></p><p>As you can see the true state behaves somewhat erratically, especially $x_2$ as directly affected by the noise.
The same can be said for the filter estimates.
Whereas the smoother estimates are indeed significantly smoother and qualitatively more accurate (closer to the true state).</p><p>A plot for the noise during one run is depicted below.</p><p><a href=figs/noise_sample.svg><img loading=lazy src=figs/noise_sample.svg alt=noise_sample></a></p><p>It&rsquo;s hard to say for certain just by one sample, but it looks like the smoother is able to estimate some &#171;trends&#187; in the noise sequence when they occur.</p><h2 id=comparison-of-sample-rms-and-estimated-sd>Comparison of sample RMS and estimated SD<a hidden class=anchor aria-hidden=true href=#comparison-of-sample-rms-and-estimated-sd>#</a></h2><p>Below plots with sample root mean squared errors (RMS) and estimated standard deviations (SD) for $x_1, x_2$ and $w$ are presented.</p><p><a href=figs/compare_x1.svg><img loading=lazy src=figs/compare_x1.svg alt=compare_x1>
</a><a href=figs/compare_x2.svg><img loading=lazy src=figs/compare_x2.svg alt=compare_x2></a></p><p>A plot for $w$ is done with a narrow y-axis range to demonstrate the difference between all depicted data.</p><p><a href=figs/compare_w.svg><img loading=lazy src=figs/compare_w.svg alt=compare_w></a></p><p>We can make the following observations:</p><ol><li>The agreement between sample RMS and estimated SD is very good</li><li>The smoother does indeed gives lower error RMS than the filter</li><li>The steady state smoother RMS is lower by the factor of approximately $\sqrt{2}$ compared to the filter RMS</li><li>The smoother performance is worse near the start and terminal epochs</li><li>The noise vectors are marginally observable in this model, i. e. the smoother error RMS and SD are slightly lower than the noise standard deviation</li></ol><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>Using Monte Carlo simulation I&rsquo;ve demonstrated that Kalman filter and smoother generates estimates with statistical properties consistent with their internal covariance estimates.
It is also true for the noise estimates of the Kalman smoother, which is not well known in the estimation literature and might seem somewhat dubious at first.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://nmayorov.github.io>Navigating Uncertainty</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>