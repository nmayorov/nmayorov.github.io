<!doctype html><html lang=en><head><title>Verification of Kalman filter and smoother algorithms Â· My Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=description content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method Link to heading The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><meta name=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Verification of Kalman filter and smoother algorithms"><meta name=twitter:description content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method Link to heading The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><meta property="og:title" content="Verification of Kalman filter and smoother algorithms"><meta property="og:description" content="In the previous post I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm. Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.
Monte Carlo method Link to heading The invaluable method of verification of estimation algorithms is Monte Carlo simulation:
Generate a ground truth sequence of states and measurements according to the system model. It assumes generating process and measurement noises as pseudorandom numbers Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$, where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$ Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$ The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm."><meta property="og:type" content="article"><meta property="og:url" content="https://nmayorov.github.io/posts/verify_smoother/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-29T00:00:00+00:00"><meta property="article:modified_time" content="2022-11-29T00:00:00+00:00"><link rel=canonical href=https://nmayorov.github.io/posts/verify_smoother/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.c4d7e93a158eda5a65b3df343745d2092a0a1e2170feeec909b8a89443903c6a.css integrity="sha256-xNfpOhWO2lpls980N0XSCSoKHiFw/u7JCbiolEOQPGo=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.115.3"></head><body class="preload-transitions colorscheme-light"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>My Blog</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Posts</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://nmayorov.github.io/posts/verify_smoother/>Verification of Kalman filter and smoother algorithms</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2022-11-29T00:00:00Z>November 29, 2022</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
6-minute read</span></div></div></header><div><p>In the <a href=https://nmayorov.github.io/posts/rts_as_optimization/>previous post</a> I&rsquo;ve derived formulas for a batch state estimation &#171;Kalman smoother&#187; algorithm.
Here I want to provide a numerical verification of its correctness along with the classical Kalman filter algorithm.</p><h1 id=monte-carlo-method>Monte Carlo method
<a class=heading-link href=#monte-carlo-method><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>The invaluable method of verification of estimation algorithms is Monte Carlo simulation:</p><ol><li>Generate a ground truth sequence of states and measurements according to the system model.
It assumes generating process and measurement noises as pseudorandom numbers</li><li>Run the estimation algorithm and compute its estimation errors as $\Delta x_k = \hat{x}_k - x_k$,
where $\hat{x}_k$ and $x_k$ are the estimated and true state respectively at epoch $k$</li><li>Repeat steps 1 and 2 many times and compute sample mean and covariance of the errors $\Delta x_k$ for each epoch $k$</li></ol><p>The sample mean must be close to zero and the sample covariance must match the covariance estimated by the algorithm.
Alternatively sample root mean squared errors (as $\sqrt{\operatorname{E} [\Delta x_k]_i^2}$) can be compared with standard deviations provided by the estimation algorithm.
This will check mean and covariance correctness simultaneously and this is the approach I usually use.</p><p>I will use this method to verify the Kalman filter and smoother algorithms applied to the system described in the next section.</p><h1 id=model-formulation>Model formulation
<a class=heading-link href=#model-formulation><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>As a dynamic system I consider a damped linear oscillator which is described by the following differential equation for $y$:
$$\ddot{y} + 2 \eta \omega \dot{y} + \omega^2 y = f$$
With $\omega > 0$ being the oscillator frequency and $\eta \geq 0$ being a dimensionless damping factor and $f$ being an external force.</p><p>Introducing the variables
$$
x_1 \coloneqq y \\
x_2 \coloneqq \dot{y} \\
$$
we rewrite it as a first order system
$$
\begin{bmatrix}
\dot{x}_1 \\
\dot{x}_2
\end{bmatrix} = \begin{bmatrix}
0 & 1 \\
-\omega^2 & -2 \eta \omega
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix} + \begin{bmatrix}
0 \\
1
\end{bmatrix} f
$$</p><p>Further we assume that $f$ is a white noise process with a known power spectral density $q_f^2$.
In this form we have a linear continuous stochastic process for $x$.
To convert it to an equivalent discrete form we use a first-order discretization scheme.
Let $\tau$ be the sampling period and
$$
x_k \coloneqq x(k \tau)
$$
Then the discrete time system is
$$
\begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_{k + 1} = \begin{bmatrix}
1 & \tau \\
-\omega^2 \tau & 1 - 2 \eta \omega \tau
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_k + \begin{bmatrix}
0 \\
1
\end{bmatrix} w_k
$$
With $w_k$ being a white random sequence with the variance $q_f^2 \tau$.</p><p>Noisy measurements of $x_1$ and $x_2$ are available for each $k$ as
$$
\begin{bmatrix}
z_1 \\
z_2
\end{bmatrix}_k =
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} \begin{bmatrix}
x_1 \\
x_2
\end{bmatrix}_k + \begin{bmatrix}
v_1 \\
v_2
\end{bmatrix}_k
$$</p><p>Knowledge on prior statistics on $x_0$ is also available:
$$
\operatorname{E} x_0 = x_0^- \\
\operatorname{E} (x_0 - x_0^-)(x_0 - x_0^-)^T = P_0^-
$$</p><h2 id=model-summary>Model summary
<a class=heading-link href=#model-summary><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>We have formulated a discrete time linear stochastic model in the <a href=https://nmayorov.github.io/posts/rts_as_optimization/#problem-formulation>standard form</a>.
The required matrices have the following form for our problem (they don&rsquo;t depend on $k$).</p><p>Prior mean:
$$
x_0^- = \begin{bmatrix}
x_{01}^- \\
x_{02}^-
\end{bmatrix}
$$</p><p>Prior covariance matrix:
$$
P_0^- = \begin{bmatrix}
\sigma_{01}^2 & 0 \\
0 & \sigma_{02}^2
\end{bmatrix}
$$</p><p>Transition matrix:
$$
F = \begin{bmatrix}
1 & \tau \\
-\omega^2 \tau & 1 - 2 \eta \omega \tau
\end{bmatrix}
$$</p><p>Process noise input matrix:
$$
G = \begin{bmatrix}
0 \\
1
\end{bmatrix}
$$</p><p>Process noise covariance matrix:
$$
Q = \begin{bmatrix}
q_f^2 \tau
\end{bmatrix}
$$</p><p>Measurement matrix:
$$
H = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$</p><p>Measurement noise covariance matrix:
$$
R = \begin{bmatrix}
\sigma^2_{z1} & 0 \\
0 & \sigma^2_{z2}
\end{bmatrix}
$$</p><h2 id=numerical-values>Numerical values
<a class=heading-link href=#numerical-values><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Here I define which numerical values will be used in the simulation.
For intuitiveness I assume that $x_1$ is measured in radians and $x_2$ in radians per second (imagine a simple gravity pendulum).
Then dimensions of the other variables follow.</p><p>$$
\omega = \frac{2 \pi}{10} \, \text{Hz (period of 10 s)} \\
\eta = 0.1 \\
q_f = 0.03 \, \frac{\text{rad}}{\text{s}\sqrt{\text{s}}} \\
\sigma_{z1} = 0.2 \, \text{rad} \\
\sigma_{z2} = 0.1 \, \frac{\text{rad}}{\text{s}} \\
x_{01}^- = 1 \, \text{rad} \\
x_{02}^- = 0 \, \frac{\text{rad}}{\text{s}} \\
\sigma_{01}^- = 0.1 \, \text{rad} \\
\sigma_{02}^- = 0.05 \, \frac{\text{rad}}{\text{s}} \\
\tau = 0.1 \, \text{s}
$$</p><h1 id=simulation-results>Simulation results
<a class=heading-link href=#simulation-results><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>I have used 10000 runs in the simulation.
In each run the state for 1000 epochs was computed.
For brevity and simplicity I don&rsquo;t analyze correlation between the states (off-diagonal elements of the covariance).</p><h2 id=plots-for-a-single-simulation-run>Plots for a single simulation run
<a class=heading-link href=#plots-for-a-single-simulation-run><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Plots of the variables for one run are depicted below.
The plots in the second row enlarges the end part of the plots in the first row.</p><p><a href=figs/state_sample.svg><img src=figs/state_sample.svg alt=state_sample></a></p><p>As you can see the true state behaves somewhat erratically, especially $x_2$ as directly affected by the noise.
The same can be said for the filter estimates.
Whereas the smoother estimates are indeed significantly smoother and qualitatively more accurate (closer to the true state).</p><p>A plot for the noise during one run is depicted below.</p><p><a href=figs/noise_sample.svg><img src=figs/noise_sample.svg alt=noise_sample></a></p><p>It&rsquo;s hard to say for certain just by one sample, but it looks like the smoother is able to estimate some &#171;trends&#187; in the noise sequence when they occur.</p><h2 id=comparison-of-sample-rms-and-estimated-sd>Comparison of sample RMS and estimated SD
<a class=heading-link href=#comparison-of-sample-rms-and-estimated-sd><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Below plots with sample root mean squared errors (RMS) and estimated standard deviations (SD) for $x_1, x_2$ and $w$ are presented.</p><p><a href=figs/compare_x1.svg><img src=figs/compare_x1.svg alt=compare_x1></a>
<a href=figs/compare_x2.svg><img src=figs/compare_x2.svg alt=compare_x2></a></p><p>A plot for $w$ is done with a narrow y-axis range to demonstrate the difference between all depicted data.</p><p><a href=figs/compare_w.svg><img src=figs/compare_w.svg alt=compare_w></a></p><p>We can make the following observations:</p><ol><li>The agreement between sample RMS and estimated SD is very good</li><li>The smoother does indeed gives lower error RMS than the filter</li><li>The steady state smoother RMS is lower by the factor of approximately $\sqrt{2}$ compared to the filter RMS</li><li>The smoother performance is worse near the start and terminal epochs</li><li>The noise vectors are marginally observable in this model, i. e. the smoother error RMS and SD are slightly lower than the noise standard deviation</li></ol><h1 id=conclusion>Conclusion
<a class=heading-link href=#conclusion><i class="fa fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h1><p>Using Monte Carlo simulation I&rsquo;ve demonstrated that Kalman filter and smoother generates estimates with statistical properties consistent with their internal covariance estimates.
It is also true for the noise estimates of the Kalman smoother, which is not well known in the estimation literature and might seem somewhat dubious at first.</p></div><footer></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>Â©
2023
Â·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.</section></footer></main><script src=/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js integrity="sha256-I2BJOV3DaC+ycZZAhylY4S8fJAZ7sJwyeyM+YpDH7aw="></script></body></html>