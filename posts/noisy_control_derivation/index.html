<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Rigorous consideration of noisy control input in Kalman filter state propagation | Navigating Uncertainty</title>
<meta name=keywords content><meta name=description content="In a previous post I&rsquo;ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters.
Here I want to develop a more rigorous view to this approach.
Problem formulation
Let&rsquo;s consider a linear state transition equation for $x_k$ of the form:
$$
x_{k + 1} = F_k x_k + B_k u_k,
$$
where $u_k$ is the deterministic sequence of control vectors.
Initial distribution of $x$ is given as normal:
$$
x_0 \sim \mathcal{N}(\hat{x}_0, P_0)
$$"><meta name=author content="Nikolay Mayorov"><link rel=canonical href=https://nmayorov.github.io/posts/noisy_control_derivation/><link crossorigin=anonymous href=/assets/css/stylesheet.2bf60e0c06fa2260ec89bda82b16e279786ebbefb017df7d2d7785db558ea2c7.css integrity="sha256-K/YODAb6ImDsib2oKxbieXhuu++wF999LXeF21WOosc=" rel="preload stylesheet" as=style><link rel=icon href=https://nmayorov.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://nmayorov.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://nmayorov.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://nmayorov.github.io/apple-touch-icon.png><link rel=mask-icon href=https://nmayorov.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://nmayorov.github.io/posts/noisy_control_derivation/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script><meta property="og:url" content="https://nmayorov.github.io/posts/noisy_control_derivation/"><meta property="og:site_name" content="Navigating Uncertainty"><meta property="og:title" content="Rigorous consideration of noisy control input in Kalman filter state propagation"><meta property="og:description" content="In a previous post I’ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters. Here I want to develop a more rigorous view to this approach.
Problem formulation Let’s consider a linear state transition equation for $x_k$ of the form: $$ x_{k + 1} = F_k x_k + B_k u_k, $$ where $u_k$ is the deterministic sequence of control vectors. Initial distribution of $x$ is given as normal: $$ x_0 \sim \mathcal{N}(\hat{x}_0, P_0) $$"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-20T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Rigorous consideration of noisy control input in Kalman filter state propagation"><meta name=twitter:description content="In a previous post I&rsquo;ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters.
Here I want to develop a more rigorous view to this approach.
Problem formulation
Let&rsquo;s consider a linear state transition equation for $x_k$ of the form:
$$
x_{k + 1} = F_k x_k + B_k u_k,
$$
where $u_k$ is the deterministic sequence of control vectors.
Initial distribution of $x$ is given as normal:
$$
x_0 \sim \mathcal{N}(\hat{x}_0, P_0)
$$"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nmayorov.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Rigorous consideration of noisy control input in Kalman filter state propagation","item":"https://nmayorov.github.io/posts/noisy_control_derivation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Rigorous consideration of noisy control input in Kalman filter state propagation","name":"Rigorous consideration of noisy control input in Kalman filter state propagation","description":"In a previous post I\u0026rsquo;ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters. Here I want to develop a more rigorous view to this approach.\nProblem formulation Let\u0026rsquo;s consider a linear state transition equation for $x_k$ of the form: $$ x_{k + 1} = F_k x_k + B_k u_k, $$ where $u_k$ is the deterministic sequence of control vectors. Initial distribution of $x$ is given as normal: $$ x_0 \\sim \\mathcal{N}(\\hat{x}_0, P_0) $$\n","keywords":[],"articleBody":"In a previous post I’ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters. Here I want to develop a more rigorous view to this approach.\nProblem formulation Let’s consider a linear state transition equation for $x_k$ of the form: $$ x_{k + 1} = F_k x_k + B_k u_k, $$ where $u_k$ is the deterministic sequence of control vectors. Initial distribution of $x$ is given as normal: $$ x_0 \\sim \\mathcal{N}(\\hat{x}_0, P_0) $$\nNow imagine that only noisy measurements $\\tilde{u}_k$ of control signals are available (think IMU readings in INS). To be specific let’s assume $$ \\tilde{u}_k = u_k + w_k, \\text{with } w_k \\sim \\mathcal{N}(0, Q_k) $$\nQuite naturally the prediction step of a Kalman filter for this formulation has the form: $$ \\hat{x}_{k + 1} = F_k \\hat{x}_k + B_k \\tilde{u}_k \\\\ P_{k + 1} = F_k P_k F_k^T + B_k Q_k B_k^T $$ Where $\\hat{x}_k$ and $P_k$ are conditional mean and covariance, the mean being the optimal estimate by all criteria.\nIt makes sense intuitively and was empirically explained for an error state of a nonlinear problem in my post linked above. However, how do we exactly derive these equations in a rigorous way similarly to [1]? How do we interpret the result? Are these the same conditional mean and covariance arising from Bayesian approach?\nConceptual solution The easiest satisfactory solution I’ve found is to consider a control input vector as a part of an augmented state vector. Then we can proceed with the following reasoning:\nThe availability of a measured control $u_k$ is nothing but a measurement, which we already know how to handle The fact that we use these measurements means that our estimated mean and covariance are conditioned on these noisy control measurements The fact that we apply the same steps – measurement and prediction, allows for exactly the same interpretation of linear Kalman filter as derived in [1] Before moving on to the detailed solution let’s consider a supplementary problem.\nState initialization from complete uncertainty by a measurement Consider a situation where we start from a complete uncertainty for the state vector $x$ and receive a measurement of the form: $$ z = x + v, v \\sim \\mathcal{N}(0, R) $$\nBy the Bayes rule we can compute a posterior distribution: $$ p(x | z) \\propto p(z | x) p (x) \\propto p(z | x) = \\mathcal{N}(z | x, R) = \\mathcal{N}(x | z, R) $$ Here we’ve used that $p(x)$ is constant (i.e. complete uncertainty) and that the normal distribution is symmetric with respect to the argument and the mean. The result holds for other noise distributions as long as its PDF depends only on the absolute deviation from the mean.\nThis result means that if, for example, a GPS receiver delivers a rover position $\\tilde{p}$ with uncertainty covariance $R$ then it is correct to describe the knowledge of our position as a normal distribution $\\mathcal{N}(\\tilde{p}, R)$. Note that the measurement process starts with the true position $p$ and adds the noise to it. I believe this result is more subtle than people realize and not trivially «intuitive». It can be correctly understood only in a Bayesian paradigm as a posterior conditional distribution.\nIn practice, we skip this derivation and directly initialize state mean and covariance (or their parts) from such measurements (keeping in mind its exact meaning).\nDetailed technical solution Now let’s formally derive how we should update conditional mean and covariance from epoch $k$ to $k + 1$. First we formally introduce an augmented state vector including the control signal: $$ x^a_k = \\begin{bmatrix} x_k \\\\ u_k \\end{bmatrix} $$\nAt this point we can assume that $u_k$ is completely uncertain. As described in the previous section we initialize it by processing the measurement $\\tilde{u}_k$ to get the following conditional mean and covariance: $$ \\hat{x}^a_k = \\begin{bmatrix} \\hat{x}_k \\\\ \\tilde{u}_k \\end{bmatrix} \\\\ P^a_k = \\begin{bmatrix} P_k \u0026 0 \\\\ 0 \u0026 Q_k \\end{bmatrix} $$\nThe transition equation can be written for the augmented vector in the form: $$ x^a_{k + 1} = F^a_k x^a_k, \\text{where } F^a_k = \\begin{bmatrix} F_k \u0026 B_k \\\\ 0 \u0026 0 \\end{bmatrix} $$ The prediction of the augmented condition mean and covariance has the simple form: $$ \\hat{x}^a_{k + 1} = F^a_k \\hat{x}^a_k \\\\ P^a_{k + 1} = F^a_k P^a_k (F^a_k)^T $$ Substituting all the augmented forms and keeping the result only for $\\hat{x}$ and $P$ we get: $$ \\hat{x}_{k + 1} = F_k \\hat{x}_k + B_k \\tilde{u}_k \\\\ P_{k + 1} = F_k P_k F_k^T + B_k Q_k B_k^T $$ We’ve arrived to the expected result.\nFor nonlinear estimation algorithms we use this result as a building block and apply usual linearization techniques etc. with the same justification.\nConclusion Here I’ve presented a somewhat tedious and formal deviation which showed that the noisy control inputs often arising in estimation problems can be treated in a usual intuitive manner while staying in the rigorous Bayesian framework.\nReferences P. S. Maybeck «Stochastic Models Estimation and Control, Vol. 1» ","wordCount":"838","inLanguage":"en","datePublished":"2024-12-20T00:00:00Z","dateModified":"2024-12-20T00:00:00Z","author":{"@type":"Person","name":"Nikolay Mayorov"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nmayorov.github.io/posts/noisy_control_derivation/"},"publisher":{"@type":"Organization","name":"Navigating Uncertainty","logo":{"@type":"ImageObject","url":"https://nmayorov.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nmayorov.github.io/ accesskey=h title="Navigating Uncertainty (Alt + H)">Navigating Uncertainty</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nmayorov.github.io/open_source title="Open source"><span>Open source</span></a></li><li><a href=https://nmayorov.github.io/archives title="All posts"><span>All posts</span></a></li><li><a href=https://nmayorov.github.io/tags title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nmayorov.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://nmayorov.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Rigorous consideration of noisy control input in Kalman filter state propagation</h1><div class=post-meta><span title='2024-12-20 00:00:00 +0000 UTC'>December 20, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Nikolay Mayorov</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#problem-formulation aria-label="Problem formulation">Problem formulation</a></li><li><a href=#conceptual-solution aria-label="Conceptual solution">Conceptual solution</a></li><li><a href=#state-initialization-from-complete-uncertainty-by-a-measurement aria-label="State initialization from complete uncertainty by a measurement">State initialization from complete uncertainty by a measurement</a></li><li><a href=#detailed-technical-solution aria-label="Detailed technical solution">Detailed technical solution</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><p>In a <a href=https://nmayorov.github.io/posts/time_propagation_noise/>previous post</a> I&rsquo;ve considered an intuitive engineering approach of handling noisy control input signals in Extended Kalman Filters.
Here I want to develop a more rigorous view to this approach.</p><h1 id=problem-formulation>Problem formulation<a hidden class=anchor aria-hidden=true href=#problem-formulation>#</a></h1><p>Let&rsquo;s consider a linear state transition equation for $x_k$ of the form:
$$
x_{k + 1} = F_k x_k + B_k u_k,
$$
where $u_k$ is the deterministic sequence of control vectors.
Initial distribution of $x$ is given as normal:
$$
x_0 \sim \mathcal{N}(\hat{x}_0, P_0)
$$</p><p>Now imagine that only noisy measurements $\tilde{u}_k$ of control signals are available (think IMU readings in INS).
To be specific let&rsquo;s assume
$$
\tilde{u}_k = u_k + w_k, \text{with } w_k \sim \mathcal{N}(0, Q_k)
$$</p><p>Quite naturally the prediction step of a Kalman filter for this formulation has the form:
$$
\hat{x}_{k + 1} = F_k \hat{x}_k + B_k \tilde{u}_k \\
P_{k + 1} = F_k P_k F_k^T + B_k Q_k B_k^T
$$
Where $\hat{x}_k$ and $P_k$ are conditional mean and covariance, the mean being the optimal estimate by all criteria.</p><p>It makes sense intuitively and was empirically explained for an error state of a nonlinear problem in my post linked above.
However, how do we exactly derive these equations in a rigorous way similarly to [1]?
How do we interpret the result?
Are these the same conditional mean and covariance arising from Bayesian approach?</p><h1 id=conceptual-solution>Conceptual solution<a hidden class=anchor aria-hidden=true href=#conceptual-solution>#</a></h1><p>The easiest satisfactory solution I&rsquo;ve found is to consider a control input vector as a part of an augmented state vector.
Then we can proceed with the following reasoning:</p><ol><li>The availability of a measured control $u_k$ is nothing but a <em>measurement</em>, which we already know how to handle</li><li>The fact that we use these measurements means that our estimated mean and covariance are <em>conditioned</em> on these noisy control measurements</li><li>The fact that we apply the same steps &ndash; measurement and prediction, allows for exactly the same interpretation of linear Kalman filter as derived in [1]</li></ol><p>Before moving on to the detailed solution let&rsquo;s consider a supplementary problem.</p><h1 id=state-initialization-from-complete-uncertainty-by-a-measurement>State initialization from complete uncertainty by a measurement<a hidden class=anchor aria-hidden=true href=#state-initialization-from-complete-uncertainty-by-a-measurement>#</a></h1><p>Consider a situation where we start from a complete uncertainty for the state vector $x$ and receive a measurement of the form:
$$
z = x + v, v \sim \mathcal{N}(0, R)
$$</p><p>By the Bayes rule we can compute a posterior distribution:
$$
p(x | z) \propto p(z | x) p (x) \propto p(z | x) = \mathcal{N}(z | x, R) = \mathcal{N}(x | z, R)
$$
Here we&rsquo;ve used that $p(x)$ is constant (i.e. complete uncertainty) and that the normal distribution is symmetric with respect to the argument and the mean.
The result holds for other noise distributions as long as its PDF depends only on the absolute deviation from the mean.</p><p>This result means that if, for example, a GPS receiver delivers a rover position $\tilde{p}$ with uncertainty covariance $R$ then it is correct to describe the knowledge of our position as a normal distribution $\mathcal{N}(\tilde{p}, R)$.
Note that the measurement process starts with the <em>true</em> position $p$ and adds the noise to it.
I believe this result is more subtle than people realize and not trivially &#171;intuitive&#187;.
It can be correctly understood only in a Bayesian paradigm as a posterior conditional distribution.</p><p>In practice, we skip this derivation and directly initialize state mean and covariance (or their parts) from such measurements (keeping in mind its exact meaning).</p><h1 id=detailed-technical-solution>Detailed technical solution<a hidden class=anchor aria-hidden=true href=#detailed-technical-solution>#</a></h1><p>Now let&rsquo;s formally derive how we should update conditional mean and covariance from epoch $k$ to $k + 1$.
First we formally introduce an augmented state vector including the control signal:
$$
x^a_k = \begin{bmatrix} x_k \\ u_k \end{bmatrix}
$$</p><p>At this point we can assume that $u_k$ is completely uncertain.
As described in the previous section we initialize it by processing the measurement $\tilde{u}_k$ to get the following conditional mean and covariance:
$$
\hat{x}^a_k = \begin{bmatrix}
\hat{x}_k \\
\tilde{u}_k
\end{bmatrix} \\
P^a_k = \begin{bmatrix}
P_k & 0 \\
0 & Q_k
\end{bmatrix}
$$</p><p>The transition equation can be written for the augmented vector in the form:
$$
x^a_{k + 1} = F^a_k x^a_k, \text{where }
F^a_k = \begin{bmatrix}
F_k & B_k \\
0 & 0
\end{bmatrix}
$$
The prediction of the augmented condition mean and covariance has the simple form:
$$
\hat{x}^a_{k + 1} = F^a_k \hat{x}^a_k \\
P^a_{k + 1} = F^a_k P^a_k (F^a_k)^T
$$
Substituting all the augmented forms and keeping the result only for $\hat{x}$ and $P$ we get:
$$
\hat{x}_{k + 1} = F_k \hat{x}_k + B_k \tilde{u}_k \\
P_{k + 1} = F_k P_k F_k^T + B_k Q_k B_k^T
$$
We&rsquo;ve arrived to the expected result.</p><p>For nonlinear estimation algorithms we use this result as a building block and apply usual linearization techniques etc. with the same justification.</p><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>Here I&rsquo;ve presented a somewhat tedious and formal deviation which showed that the noisy control inputs often arising in estimation problems can be treated in a usual intuitive manner while staying in the rigorous Bayesian framework.</p><h1 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h1><ol><li>P. S. Maybeck &#171;Stochastic Models Estimation and Control, Vol. 1&#187;</li></ol></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://nmayorov.github.io/>Navigating Uncertainty</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>